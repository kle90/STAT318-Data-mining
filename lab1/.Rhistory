a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum((((g(xi[1:i]) + 0.5) - mean(((g(xi[1:i]))) + 0.5))^2))
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.975, lty=2, col="tomato")
set.seed(48792793)
### For when x = 1.644854
n <- 10000
g <- function(t) (1/sqrt(2*pi)) * exp((-t^2)/2)
b <- 1.644854
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
lhs <- 0.5
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum(((g(xi[1:i]) + 0.5) - mean(((g(xi[1:i]))) + 0.5)^2))
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.95, lty=2, col="tomato")
set.seed(48792793)
### For when x = 1.644854
n <- 10000
g <- function(t) (1/sqrt(2*pi)) * exp((-t^2)/2)
b <- 1.644854
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
lhs <- 0.5
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum((((g(xi[1:i]) + 0.5) - mean(((g(xi[1:i]))) + 0.5))^2))
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.95, lty=2, col="tomato")
### For when x = 1.959964
b <- 1.959964
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum((((g(xi[1:i]) + 0.5) - mean(((g(xi[1:i]))) + 0.5))^2))
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.975, lty=2, col="tomato")
set.seed(48792793)
### For when x = 1.644854
n <- 10000
g <- function(t) (1/sqrt(2*pi)) * exp((-t^2)/2)
b <- 1.644854
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
lhs <- 0.5
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum(((g(xi[1:i]) + 0.5) - mean(g(xi[1:i]) + 0.5))^2)
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.95, lty=2, col="tomato")
### For when x = 1.959964
b <- 1.959964
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum(((g(xi[1:i]) + 0.5) - mean(g(xi[1:i]) + 0.5))^2)
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.975, lty=2, col="tomato")
set.seed(48792793)
g_of_x <- function(x) exp(-sqrt(x))
n <- 10000
a <- 0
b <- 1
### Q3 a
uni_xi <- runif(n, a, b)
uni_gxi <- g_of_x(uni_xi)
(b-a) * mean(uni_gxi)
### Q3 b
beta_xi <- rbeta(n, 0.8, 1)
beta_gxi <- g_of_x(beta_xi)
(b-a) * mean(beta_gxi)
### Q3 c
### Uniform sampling CI
uni_int_est <- uni_var_est <- numeric(length=n-1)
for (i in 2:n){
uni_int_est[i-1] <- (b-a) * mean(g_of_x(uni_xi[1:i]))
uni_var_est[i-1] <- (((b-a)^2)/(i-1)) * sum((g_of_x(uni_xi[1:i]) - mean(g_of_x(uni_xi[1:i])))^2)
}
cil_uni <- uni_int_est -  qnorm(0.99) * sqrt(uni_var_est/(2:n))
ciu_uni <- uni_int_est +  qnorm(0.99) * sqrt(uni_var_est/(2:n))
plot(2:n, uni_int_est, xlab = "Sample size n", ylab = "Approximation",
type = "l", ylim = c(min(cil_uni), max(ciu_uni)))
lines(2:n, cil_uni, lty=2)
lines(2:n, ciu_uni, lty=2)
abline(h=0.5285, lty=2, col="red")
### Beta sampling CI
beta_int_est <- beta_var_est <- numeric(length=n-1)
for (i in 2:n){
beta_int_est[i-1] <- (b-a) * mean(g_of_x(beta_xi[1:i]))
beta_var_est[i-1] <- (((b-a)^2)/(i-1)) * sum((g_of_x(beta_xi[1:i]) - mean(g_of_x(beta_xi[1:i])))^2)
}
cil_beta <- beta_int_est -  qnorm(0.99) * sqrt(beta_var_est/(2:n))
ciu_beta <- beta_int_est +  qnorm(0.99) * sqrt(beta_var_est/(2:n))
plot(2:n, beta_int_est, xlab = "Sample size n", ylab = "Approximation",
type = "l", ylim = c(min(cil_beta), max(ciu_beta)))
lines(2:n, cil_beta, lty=2)
lines(2:n, ciu_beta, lty=2)
abline(h=0.5285, lty=2, col="tomato")
set.seed(48792793)
### For when x = 1.644854
n <- 10000
g <- function(t) (1/sqrt(2*pi)) * exp((-t^2)/2)
b <- 1.644854
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
lhs <- 0.5
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum(((g(xi[1:i]) + 0.5) - mean(g(xi[1:i]) + 0.5))^2)
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.95, lty=2, col="tomato")
### For when x = 1.959964
b <- 1.959964
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum(((g(xi[1:i]) + 0.5) - mean(g(xi[1:i]) + 0.5))^2)
}
### For when x = 1.959964
b <- 1.959964
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum(((g(xi[1:i]) + 0.5) - mean(g(xi[1:i]) + 0.5))^2)
}
int_est
int_est <- var_est <- numeric(length=n-1)
int_est
var_est
### For when x = 1.959964
b <- 1.959964
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum(((g(xi[1:i]) + 0.5) - mean(g(xi[1:i]) + 0.5))^2)
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.975, lty=2, col="tomato")
set.seed(48792793)
### For when x = 1.644854
n <- 10000
g <- function(t) (1/sqrt(2*pi)) * exp((-t^2)/2)
b <- 1.644854
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
lhs <- 0.5
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum(((g(xi[1:i]) + 0.5) - mean(g(xi[1:i]) + 0.5))^2)
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.95, lty=2, col="tomato")
### For when x = 1.959964
b <- 1.959964
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum(((g(xi[1:i]) + 0.5) - mean(g(xi[1:i]) + 0.5))^2)
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.975, lty=2, col="tomato")
set.seed(48792793)
g_of_x <- function(x) exp(-x) * sin(x)
b <- 2*pi
a <- 0
n <- 100
xi <- runif(n, a, b)
gxi <- g_of_x(xi)
est_val <- (b-a) * mean(gxi)
sprintf("The estimated value is %f", est_val)
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n) {
int_est[i-1] <- (b-a) * mean(g_of_x(xi[1:i]))
var_est[i-1] <- (((b-a)^2) / (i-1)) * sum((g_of_x(xi[1:i]) - mean(g_of_x(xi[1:i])))^2)
}
ci_lower <- int_est - qnorm(0.9) * sqrt(var_est/(2:n))
ci_upper <- int_est + qnorm(0.9) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab="Sample size n", ylab="MC Approximation", type="l",
ylim=c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
### For when x = 1.644854
n <- 10000
g <- function(t) (1/sqrt(2*pi)) * exp((-t^2)/2)
b <- 1.644854
a <- 0
xi <- runif(n, a, b)
gxi <- g(xi)
lhs <- 0.5
rhs_est_val <- (b-a) * mean(gxi)
rhs_est_val
lhs + rhs_est_val
### Confidence interval
int_est <- var_est <- numeric(length=n-1)
for (i in 2:n){
int_est[i-1] <- (b-a) * mean(g(xi[1:i])) + 0.5
var_est[i-1] <- (b-a)/(i-1) * sum(((g(xi[1:i]) + 0.5) - mean(g(xi[1:i]) + 0.5))^2)
}
ci_lower <- int_est -  qnorm(0.95) * sqrt(var_est/(2:n))
ci_upper <- int_est +  qnorm(0.95) * sqrt(var_est/(2:n))
plot(2:n, int_est, xlab = "Sample size n", ylab = "NC approximation",
type = "l", ylim = c(min(ci_lower), max(ci_upper)))
lines(2:n, ci_lower, lty=2)
lines(2:n, ci_upper, lty=2)
abline(h=0.95, lty=2, col="tomato")
x <- rexp(100, rate = 2)
set.seed(987654321)
x <- rexp(100, rate = 2)
lambda1 <-log(2)/median(x)
lambda2 <- 1/mean(x)
c(lambda1, lambda2)
####
ests <- replicate(10000, {
x <- rexp(10, rate = 2)
lambda1 <-log(2)/median(x)
lambda2 <- 1/mean(x)
c(lambda1, lambda2)
return(c(lambda1, lambda2))
})
ests
ests[, 1:5]
apply(ests, 1, function(x) mean(x) - 2)
apply(ests, 1, function(x) sd(x))
n = 25 # sample size
N = 10000 # number of bootstrap resamples
alpha = 0.05 # significance level
set.seed(1)
# Simulate correlated samples (paired) from standard normals
x = rnorm(n)
y = rnorm(n, 0.5 * x + 0.5)
plot(y ~ x)
# Combine the paired data into a matrix with two columns
xy = cbind(x, y) # 'cbind' means column bind'
xy
xy?cbind
?cbind
xy[1]
xy[1, ]
boot.pairedmean = function(xy, indices) {
xystar = xy[indices, ]
# extract resampled x and y datasets
xstar = xystar[, 1]
ystar = xystar[, 2]
return(mean(xstar) - mean(ystar))
}
results = boot(xy, statistic = boot.pairedmean, R = N)
boot.pairedmean = function(xy, indices) {
xystar = xy[indices, ]
# extract resampled x and y datasets
xstar = xystar[, 1]
ystar = xystar[, 2]
return(mean(xstar) - mean(ystar))
}
results = boot(xy, statistic = boot.pairedmean, R = N)
?boot
??boot
xy[, 1]
xy
xy[, 2]
xy
nx = 20 # sample size for x
ny = 30 # sample size for y
N = 10000 # number of bootstrap resamples
alpha = 0.05 # significance level
set.seed(1)
x = rnorm(nx, mean = 0)
y = rnorm(ny, mean = 1)
xy = c(x, y)
id = as.factor(c(rep("x", nx), rep("y", ny)))
id
xy
x
?boot
??boot
x <- c(1,3,2,5)
x
x = c(1,6,2)
x
y = c(1,4,3)
length(x)
length(y)
x+y
ls()
rm(x,y)
ls()
rm(list=ls())
ls()
?matrix
x=matrix(data=c(1,2,3,4), nrow=2, ncol=2)
x
x=matrix(c(1,2,3,4),2,2)
x
matrix(c(1,2,3,4),2,2,byrow=TRUE)
sqrt(x)
x^2
x=rnorm(50)
y=x+rnorm(50,mean=50,sd=.1)
cor(x,y)
set.seed(1303)
rnorm(50)
set.seed(3)
y=rnorm(100)
mean(y)
var(y)
sqrt(var(y))
sd(y)
# You can also calculate an MSE as follows
y = c(1,2,2.5,3,4)			# measured values
# You can also calculate an MSE as follows
y = c(1,2,2.5,3,4)			# measured values
haty = c(1.1,1.9,2,2.8,4.2)         # predicted values
MSE = mean((y - haty)^2)
# or the long way
MSE = (1/length(y))*sum((y - haty)^2)
MSE
x=rnorm(100)
y=rnorm(100)
plot(x,y)
plot(x,y,xlab="this is the x-axis",ylab="this is the y-axis",main="Plot of X vs Y")
pdf("Figure.pdf")
plot(x,y,col="green")
dev.off()
getwd()
x=seq(1,10)
x
x=1:10
x
x=seq(-pi,pi,length=50)
y=x
x=seq(-pi,pi,length=50)
x
y=x
f=outer(x,y,function(x,y)cos(y)/(1+x^2))
contour(x,y,f)
contour(x,y,f)
contour(x,y,f,nlevels=45,add=T)
fa=(f-t(f))/2
contour(x,y,fa,nlevels=15)
image(x,y,fa)
persp(x,y,fa)
persp(x,y,fa,theta=30)
persp(x,y,fa,theta=30,phi=20)
persp(x,y,fa,theta=30,phi=70)
persp(x,y,fa,theta=30,phi=40)
A=matrix(1:16,4,4)
A
A[2,3]
A[c(1,3),c(2,4)]
A[1:3,2:4]
A[1:2,]
A[,1:2]
A[1,]
A[-c(1,3),]
A[-c(1,3),-c(1,3,4)]
dim(A)
Auto=read.csv("Auto.csv",header=T,na.strings="?")
fix(Auto)
Auto=na.omit(Auto)
dim(Auto)
names(Auto)
Auto=read.csv("Auto.csv",header=T,na.strings="?")
setwd("H:/Documents/STAT318/lab1")
Auto=read.csv("Auto.csv",header=T,na.strings="?")
fix(Auto)
Auto[1:4,]
Auto=na.omit(Auto)
dim(Auto)
names(Auto)
plot(cylinders, mpg)
plot(Auto$cylinders, Auto$mpg)
attach(Auto)
plot(cylinders, mpg)
cylinders=as.factor(cylinders)
plot(cylinders, mpg)
plot(cylinders, mpg, col="red")
plot(cylinders, mpg, col="red", varwidth=T)
plot(cylinders, mpg, col="red", varwidth=T,horizontal=T)
plot(cylinders, mpg, col="red", varwidth=T, xlab="cylinders", ylab="MPG")
hist(mpg)
hist(mpg,col=2)
hist(mpg,col=2,breaks=15)
pairs(Auto)
pairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)
plot(horsepower,mpg)
identify(horsepower,mpg,name)
